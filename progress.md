I first cloned the code from https://github.com/leahannah/uniTuebingenCL. I fixed some minor issues of variable names, file paths, and package installations to get the code running. 

 I tried to use ELMoEmbeddings, which is based on AllenNLP library, a library that has not been updated for a while. After initial trouble with pip install of allennlp, I switched to use conda-forge, conda environment, and google colab, which all ran into various issues. I also tried to import the ELMo model from hugging face, which also failed. Instead of using ELMoEmbeddings, I switched to use WordEmbeddings("glove") based on https://flairnlp.github.io/docs/tutorial-embeddings/flair-embeddings.The next step is to experiment with different flair embeddings and even transformers to see which one has the highest performance. 

I changed the padding in  train_model_elmo function to make sure train.csv and dev.csv get the same total length. I ran into the probelm that the nparray model expected to receive had shape (29,100) while the passed in input had shape (28,100). After investigation, I found that train_model_elmo function pad the sentences based on the sentence with the maximum length in the set. The longest sentence in train.csv has length 29 while the longest sentence in dev.csv has length 28. I changed the code to align the edited texts. 